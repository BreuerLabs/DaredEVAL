name: "plug_and_play"
stylegan_model: "stylegan2-ada-pytorch/ffhq.pkl"

evaluation_model:
  wandb_id: "zgsoc65z" # The wandb id of the run of the evaluation model. This will then extract the config and model weights from wandb.
  config_path: False #"classifiers/saved_configs/cifardropout.yaml" # The path to a config of a trained evaluation model. Weights with the same name must be in classifiers/saved_models

  # architecture: inception-v3 # architecture of evaluation model
  # weights: classifiers/saved_models/soft-wood-101.pth # link to weight file

# From the pnp repo
candidates:
  num_candidates: 10
  candidate_search:
    search_space_size: 2000
    center_crop: null
    # resize: 224 #! This is removed because it depends on dataset not on attack 
    horizontal_flip: true
    batch_size: 25
    truncation_psi: 0.5
    truncation_cutoff: 8

attack:
  batch_size: 1 # Batch size per GPU.
  num_epochs: 10 # Number of optimization iterations per batch.
  targets: 0 # Specify the targeted classes, either a single class index, a list of indices, or all.
  discriminator_loss_weight: 0.0 # Add discriminator weight.
  single_w: true # Optimize a single 512-vector. Otherwise, a distinct vector for each AdaIn operation is optimized.
  clip: false # Clip generated images in range [-1, 1].
  transformations: # Transformations applied during the optimization.
    CenterCrop:
      size: 800
    Resize:
      size: 32
      antialias: true

    RandomResizedCrop:
      size: [32, 32]
      scale: [0.9, 1.0]
      ratio: [1.0, 1.0]
      antialias: true

  optimizer: # Optimizer used for optimization. All optimizers from torch.optim are possible.
    Adam:
      lr: 0.005
      weight_decay: 0
      betas: [0.1, 0.1]

  lr_scheduler: # Option to provide a learning rate scheduler from torch.optim.
    MultiStepLR:
      milestones: [30, 40]
      gamma: 0.1

final_selection:
  samples_per_target: 50 # Number of samples to select from the set of optimized latent vectors.
  approach: transforms # Currently only transforms is available as an option.
  iterations: 100 # Number of iterations random transformations are applied.

wandb: # Options for WandB logging.
  enable_logging: false # Activate logging.
  wandb_init_args: # WandB init arguments.
    project: plug_and_play
    save_code: true
