name: "plug_and_play"
stylegan_model: "stylegan2-ada-pytorch/ffhq.pkl"

evaluation_model:
  wandb_id: "r71jl57n" # The wandb id of the run of the evaluation model. This will then extract the config and model weights from wandb.
  config_path: False #"classifiers/saved_configs/cifardropout.yaml" # The path to a config of a trained evaluation model. Weights with the same name must be in classifiers/saved_models

  # architecture: inception-v3 # architecture of evaluation model
  # weights: classifiers/saved_models/soft-wood-101.pth # link to weight file

candidates:
  num_candidates: 200
  candidate_search:
    search_space_size: 2000
    center_crop: 800
    resize: 224
    horizontal_flip: true
    batch_size: 25
    truncation_psi: 0.5
    truncation_cutoff: 8

attack:
  batch_size: 25
  num_epochs: 50
  targets: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301] # can be an int, list of ints, or "all"
  discriminator_loss_weight: 0.0
  single_w: true
  clip: false
  transformations:
    CenterCrop:
      size: 800
    Resize:
      size: 224
      antialias: true
    RandomResizedCrop:
      size: [224, 224]
      scale: [0.9, 1.0]
      ratio: [1.0, 1.0]
      antialias: true

  optimizer: # Optimizer used for optimization. All optimizers from torch.optim are possible.
    Adam:
      lr: 0.005
      weight_decay: 0
      betas: [0.1, 0.1]

  lr_scheduler: # Option to provide a learning rate scheduler from torch.optim.
    MultiStepLR:
      milestones: [30, 40]
      gamma: 0.1

final_selection:
  samples_per_target: 50 # Number of samples to select from the set of optimized latent vectors.
  approach: transforms # Currently only transforms is available as an option.
  iterations: 100 # Number of iterations random transformations are applied.

# wandb: # Options for WandB logging.
#   enable_logging: True # Activate logging.
#   wandb_init_args: # WandB init arguments.
#     project: plug_and_play
#     save_code: true

